{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb47be40-ba94-4c8f-a908-a067baab56b8",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Pe√±uela Parra}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales\n",
    "\n",
    "$\\textbf{Preliminaries}$ \n",
    "\n",
    "The libraries used here are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002a991-ba36-45c9-82ac-084484e25222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16747e8d-7dda-4112-ba4e-e496957d4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphes_reader import DelphesLoader #The class that allows us to access all paths of delphes files inside the server.\n",
    "from delphes_reader import clasificator #It contains functions to classify particles.\n",
    "from delphes_reader import root_analysis #It contains some useful functions like make_histograms or get_kinematics_row.\n",
    "from delphes_reader import Quiet #Context manager for silencing certain ROOT operations.\n",
    "\n",
    "from ROOT import TChain #It is necessary to read .root files.\n",
    "\n",
    "import pandas as pd #Python library is useful for data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62c0ed-8cad-4680-af4f-7670d7f3a30b",
   "metadata": {},
   "source": [
    "With the objective of watching Uniandes_Framework in action, we will reconstruct Z Boson Mass using some cuts and reading all background .root files. \n",
    "\n",
    "We are going to take as a starting point: **1_Read_Delphes_Files.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815f482-1f11-4441-9720-e4466fc93c0a",
   "metadata": {},
   "source": [
    "**1. Get delphes files (.root) paths.**\n",
    "\n",
    "First, we must get delphes file paths of the signal. In this case, the signal is Z Boson. To do this, we can use DelphesLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5caf3-dfbd-4dab-afc0-415f546c6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paths_Signal = DelphesLoader('Z_Tutorial').Forest\n",
    "Paths_WW = DelphesLoader('ww').Forest\n",
    "Paths_ttbar = DelphesLoader('ttbar').Forest\n",
    "Paths_stop = DelphesLoader('stop').Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f31f81-5073-4a79-87a2-080558b14688",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paths = {'z':Paths_Signal, 'ww': Paths_WW, 'ttbar': Paths_ttbar, 'stop': Paths_stop}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf69793-d95f-47c3-a9a3-7dc9e13ea4e6",
   "metadata": {},
   "source": [
    "**2. Extract information from root files to create .CSV files:**\n",
    "\n",
    "To do this, we have to read those .root files. \n",
    "\n",
    "If we want to adding cuts to the muons we have to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b0f6f-1d2a-496f-89fa-83e7b63baf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At first, we have to create a directory to save the z reconstructed kinematic information of 'z', 'ww', 'ttbar', 'stop' signals:\n",
    "Z_reconstructed_particles = {}\n",
    "\n",
    "with Quiet(): #Context manager for silencing certain ROOT operations.\n",
    "    \n",
    "    for key in Paths.keys(): #Paths.keys() is ['z', 'ww', 'ttbar', 'stop']\n",
    "                \n",
    "        for Path in Paths[key]: #Paths[key] is the list with the delphes file paths.\n",
    "            \n",
    "            #To read a .root file we have to create a Tree in ROOT and associate it the path.\n",
    "            tree = TChain(\"Delphes;1\") #Empty TChain of ROOT.\n",
    "            tree.Add(Path) #Now we associate tree with the path of a .root file.\n",
    "\n",
    "            #At this point we must go over all events in the tree, so:\n",
    "            for event in tree:\n",
    "                #Now we can use Uniandes_Framework to extract information:\n",
    "                \n",
    "                muons = clasificator.get_muons(event) #clasificator.get_muons(event) is a list that contains the muons presents in the event.\n",
    "                \n",
    "                if (len(muons) < 2): continue #The event is discarded if there are less than two muons\n",
    "                                \n",
    "                if(muons[0].GetCharge()*muons[1].GetCharge() > 0): continue #The event is discarded if they are not oppositely charged muons.\n",
    "\n",
    "                if (muons[0].pt() < 30): continue #The event is discarded if muon[0] have not a pT > 30.\n",
    "                \n",
    "                if (muons[1].pt() < 20): continue #The event is discarded if muon[1] have not a pT > 30.\n",
    "                \n",
    "            break\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390879-2497-4803-b2c3-5c3ff0345fb4",
   "metadata": {},
   "source": [
    "In fact, we can create a DataFrame to save the quantity of particles that surpass each cut. With this quantity we will be able to calculate the efficiency of each cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c204655-ca36-455c-8965-2a5493afb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At first, we have to create a dictionary to save the z reconstructed kinematic information of 'z', 'ww', 'ttbar', 'stop' signals:\n",
    "Z_reconstructed_particles = {}\n",
    "\n",
    "#We also need a dictionary \n",
    "Cutflows = {}\n",
    "\n",
    "with Quiet(): #Context manager for silencing certain ROOT operations.\n",
    "    \n",
    "    for key in Paths.keys(): #Paths.keys() is ['z', 'ww', 'ttbar', 'stop']\n",
    "                \n",
    "        for Path in Paths[key]: #Paths[key] is the list with the delphes file paths.\n",
    "            \n",
    "            #To read a .root file we have to create a Tree in ROOT and associate it the path.\n",
    "            tree = TChain(\"Delphes;1\") #Empty TChain of ROOT.\n",
    "            tree.Add(Path) #Now we associate tree with the path of a .root file.\n",
    "\n",
    "            #At this point we must go over all events in the tree, so:\n",
    "            for event in tree:\n",
    "                cut = 'All events'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                #Now we can use Uniandes_Framework to extract information:\n",
    "                \n",
    "                muons = clasificator.get_muons(event) #clasificator.get_muons(event) is a list that contains the muons presents in the event.\n",
    "                \n",
    "                if (len(muons) < 2): continue #The event is discarded if there are less than two muons\n",
    "                cut = 'Events with least two muons'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                                \n",
    "                if(muons[0].GetCharge()*muons[1].GetCharge() > 0): continue #The event is discarded if they are not oppositely charged muons.\n",
    "                cut = 'Events with oppositely charged muons'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if (muons[0].pt() < 30): continue #The event is discarded if muon[0] have not a pT > 30.\n",
    "                cut = 'Events with PT(mu[0]) > 30'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if (muons[1].pt() < 20): continue #The event is discarded if muon[1] have not a pT > 30.\n",
    "                cut = 'Events with PT(mu[1]) < 20'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "            break\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6050e6-6bdf-402a-963a-9e0ea5fcb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_Cutflows = pd.DaFrame.from_dict(Cutflows)\n",
    "DataFrame_Cutflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8700f08-6029-49f6-88d3-c6f849030312",
   "metadata": {},
   "source": [
    "Let's do this to create .csv files and cutflow file reading all .root files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e69c4-2393-468e-aaf8-02a1cf93c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At first, we have to create a directory to save the z reconstructed kinematic information of 'z', 'ww', 'ttbar', 'stop' signals:\n",
    "Z_reconstructed_particles = {}\n",
    "Cutflows = {}\n",
    "\n",
    "with Quiet(): #Context manager for silencing certain ROOT operations.\n",
    "    \n",
    "    for key in Paths.keys(): #Paths.keys() is ['z', 'ww', 'ttbar', 'stop']\n",
    "        \n",
    "        Z_reconstructed_particles[key] = [] #We have to create a list to save the kinematic information of z reconstructed for each key.\n",
    "        \n",
    "        for Path in Paths[key]: #Paths[key] is the list with the delphes file paths.\n",
    "            \n",
    "            #To read a .root file we have to create a Tree in ROOT and associate it the path.\n",
    "            tree = TChain(\"Delphes;1\") #Empty TChain of ROOT.\n",
    "            tree.Add(Path) #Now we associate tree with the path of a .root file.\n",
    "\n",
    "            #At this point we must go over all events in the tree, so:\n",
    "            for event in tree:\n",
    "                cut = 'All events'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                #Now we can use Uniandes_Framework to extract information:\n",
    "                \n",
    "                muons = clasificator.get_muons(event) #clasificator.get_muons(event) is a list that contains the muons presents in the event.\n",
    "                \n",
    "                if (len(muons) < 2): continue #The event is discarded if there are less than two muons\n",
    "                cut = 'Events with least two muons'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                                \n",
    "                if(muons[0].GetCharge()*muons[1].GetCharge() > 0): continue #The event is discarded if they are not oppositely charged muons.\n",
    "                cut = 'Events with oppositely charged muons'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if (muons[0].pt() < 30): continue #The event is discarded if muon[0] have not a pT > 30.\n",
    "                cut = 'Events with PT(mu[0]) > 30 (GeV)'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if (muons[1].pt() < 20): continue #The event is discarded if muon[1] have not a pT > 30.\n",
    "                cut = 'Events with PT(mu[1]) < 20 (GeV)'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if(abs(muons[0].eta()) > 2.4 or abs(muons[1].eta()) > 2.4): continue\n",
    "                cut = '|Eta| < 2.4 '\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                if(muons[0].DeltaR(muons[1]) < 0.3): continue\n",
    "                cut = 'DeltaR > 0.3'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                #How we can reconstruct Z Boson? We have to sum the TLorentz vector of the muon pair: \n",
    "                Z = muons[0].GetTLV() + muons[1].GetTLV()\n",
    "                \n",
    "                if(Z.M() < 66): continue\n",
    "                if(Z.M() > 116): continue\n",
    "                cut = '66 (GeV) < M(Z) < 116 (Gev)'\n",
    "                Cutflows[cut] = Cutflows.get(cut,0) + 1\n",
    "                \n",
    "                #However, Z is not an object of particle class, it is a TLV. So, we can not use root_analysis.get_kinematics_row().  \n",
    "                #If we want his kinematic information we have to create the directory by ourselves:\n",
    "                Z_kinematic_information = {\"pT_{Z}(GeV)\": Z.Pt(), \n",
    "                                           \"#eta_{Z}\": Z.Eta(), \n",
    "                                           \"#phi_{Z}\": Z.Phi(), \n",
    "                                           \"Energy_{Z}(GeV)\": Z.Energy(), \n",
    "                                           \"Mass_{Z}(GeV)\" : Z.M()} \n",
    "                \n",
    "                #This directory has the same structure of an get_kinematics_row() output. \n",
    "                \n",
    "                #Finally, we can save Z_kinematic_information for each event in a list:\n",
    "                Z_reconstructed_particles[key].append(Z_kinematic_information)  \n",
    "            break\n",
    "        break\n",
    "        \n",
    "        #At this point we have Z_reconstructed_particles[key] (a list) filled with kinematic information, so we must save it:\n",
    "        root_analysis.generate_csv(Z_reconstructed_particles[key], f'Data_{key}.csv')\n",
    "        DataFrame_Cutflows = pd.DaFrame.from_dict(Cutflows)\n",
    "        DataFrame_Cutflows.to_csv('Cutflows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426ba92-36f1-4e90-b585-9fa97b821fab",
   "metadata": {},
   "source": [
    "Until now, we created .csv files. Now we will use it to plot histograms. For this we are going to take as a starting point: **2_Histograms.ipynb**.\n",
    "\n",
    "**3. Read .csv files:**\n",
    "\n",
    "To do this, we can use pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520245b4-8e73-4c32-8394-b1137e5c6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = {'z': pd.read_csv('Data_z.csv'),\n",
    "            'stop': pd.read_csv('Data_stop.csv'),\n",
    "            'ttbar': pd.read_csv('Data_ttbar.csv'),\n",
    "            'ww': pd.read_csv('Data_ww.csv')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ffaa6-1128-4394-a3a2-832cfa1f0a49",
   "metadata": {},
   "source": [
    "**4. Create histograms:**\n",
    "\n",
    "We can use the function **root_analysis.makehistograms()**. If we want to generate all the histograms for each column on Datasets['stop'], it is enough to run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40d160-cba0-490f-b58c-36a55de10575",
   "metadata": {},
   "outputs": [],
   "source": [
    "Histos_Dictionary = {'z': root_analysis.make_histograms(Datasets['z']),\n",
    "                    'stop': root_analysis.make_histograms(Datasets['stop']),\n",
    "                    'ttbar': root_analysis.make_histograms(Datasets['ttbar']),\n",
    "                    'ww': root_analysis.make_histograms(Datasets['ww'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373c4d7-2f59-4f9f-a33e-f3e215baf075",
   "metadata": {},
   "source": [
    "**5. Overlap histograms:**\n",
    "\n",
    "We can use the function **root_analysis.overlap_histos()**. This function has two main parameters: kinematic_variable and Dict_Histos, they are a string with the name of the kinematic variable and the directory with all the histograms (it should be a directory with the same structure that we use in this tutorial) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d399d-4e80-4424-bc4a-89d0136250e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Histos, Canva, Legend = root_analysis.overlap_histos(kinematic_variable= 'Mass_{Z}(GeV)', \n",
    "                                                     Dict_Histos= Histos_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf03c5-a49e-48c6-a360-46beba248538",
   "metadata": {},
   "source": [
    "**6. Stack histograms:**\n",
    "\n",
    "For this we can use the function **root_analysis.overlap_histos()** and setting its parameter \"Stack\" as True (Boolean). However, before using Stack we have to normalized all histograms with the number of physical events. This is the reason about why we created Cutflows file.\n",
    "\n",
    "In order to calcule the number of physical events we can use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f82213-7249-45c0-b09b-30df839ed5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_events(signal):\n",
    "    cutflows = pd.read_csv('Cutflows.csv')\n",
    "    \n",
    "    Efficience = cutflows[signal][-1]/cutflows[signal][0]\n",
    "    xs = DelphesLoader(signal).xs\n",
    "    Luminosity = 10*1000\n",
    "    \n",
    "    return Efficience*Luminosity*xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed09b7-f841-442a-86a9-cd6dbba723d1",
   "metadata": {},
   "source": [
    "Let's normalizate all histograms using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dbde6-c87a-4d0f-92f7-57b3153576d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal in Histos_Dictionary.keys():\n",
    "    N = N_events(signal)\n",
    "    for histo in Histos_Dictionary[signal]:\n",
    "        histo.scale(N/histo.Integral())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca860a8-1718-42ba-87b1-70ca8527d334",
   "metadata": {},
   "source": [
    "Right now, we can stack the histograms without any problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127917e-688d-4c26-8246-91bfccb0828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Histos, Canva, Legend = root_analysis.overlap_histos(kinematic_variable= 'Mass_{Z}(GeV)', \n",
    "                                                     Dict_Histos= Histos_Dictionary,\n",
    "                                                     Stack= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b52b1-d485-4d16-a03a-ad469c984a97",
   "metadata": {},
   "source": [
    "This agrees with plots reported in: https://cds.cern.ch/record/2707171?ln=es"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
